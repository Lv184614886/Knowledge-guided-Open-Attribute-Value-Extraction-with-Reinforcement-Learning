{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"main.ipynb","provenance":[{"file_id":"1B4Tini7F3Tv_nyS8CPjm7nFz7MBclEmk","timestamp":1602484297078}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"O04pkr6Z0j4G"},"source":["#%%capture\n","print('NOTE: Intentionally crashing session to use the newly installed library.\\n')\n","!pip uninstall -y pyarrow\n","!pip install ray[debug]==0.7.5\n","# A hack to force the runtime to restart, needed to include the above dependencies.\n","import os\n","os._exit(0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"68wgJkDehIXJ"},"source":["%%capture\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xzq9OclK0pg5"},"source":["%%capture\n","!pip install python-Levenshtein\n","!pip install redis\n","!pip install -U ray\n","!pip install ray[debug]==0.7.5\n","!pip install ray[rllib]  # also recommended: ray[debug]\n","!pip uninstall -y pyarrow\n","!pip install unicodedata2\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MBUU7M16k70v"},"source":["# Main"]},{"cell_type":"markdown","metadata":{"id":"nSDz6m3g55L9"},"source":["## Import"]},{"cell_type":"code","metadata":{"id":"LedW5b8H0mki","executionInfo":{"status":"ok","timestamp":1603073885876,"user_tz":240,"elapsed":654,"user":{"displayName":"Sheng Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhraDPO3yxolOf82I55EVZaIAfn4g1oUU6mSS7k=s64","userId":"16336041814041002028"}},"outputId":"da2431a2-17ad-4e43-9633-2f05c083597c","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%tensorflow_version 1.x"],"execution_count":null,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"H1vSh2nH0rST","executionInfo":{"status":"ok","timestamp":1603072407418,"user_tz":240,"elapsed":47023,"user":{"displayName":"Sheng Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhraDPO3yxolOf82I55EVZaIAfn4g1oUU6mSS7k=s64","userId":"16336041814041002028"}},"outputId":"a05de640-50bf-44f5-8bcc-21b33cf3715c","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["import os\n","# os.chdir(\"/content/drive/My Drive/Knowledge Extraction/szhang37_code/KG_RL\") ## change to current folder\n","import tensorflow as tf\n","import pickle\n","import random\n","import pandas as pd \n","import numpy as np\n","import json\n","import time\n","from collections import Counter\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.metrics.pairwise import cosine_similarity\n","import unicodedata\n","from functools import reduce\n","#### Import ray related package\n","import ray\n","from ray.rllib.models import ModelCatalog\n","from ray.rllib.models.tf.tf_modelv2 import TFModelV2\n","from ray.rllib.models.tf.fcnet_v2 import FullyConnectedNetwork\n","\n","from ray.rllib.agents.ppo import PPOTrainer, DEFAULT_CONFIG\n","from ray.rllib.models.tf.misc import normc_initializer\n","from ray.rllib.models.tf.tf_modelv2 import TFModelV2\n","from ray.rllib.agents.dqn.distributional_q_model import DistributionalQModel\n","from ray.rllib.models.tf.visionnet_v2 import VisionNetwork as MyVisionNetwork\n","from ray.tune.logger import pretty_print\n","from ray.rllib.utils import try_import_tf\n","from ray.tune import grid_search\n","from ray.rllib.models import ModelCatalog\n","from ray.tune import Trainable\n","from ray.tune.logger import pretty_print\n","from ray.tune import run as run_tune\n","from ray.tune.registry import register_env\n","import gym\n","from gym import spaces\n","from gym.spaces import Discrete, Box\n","from ray import tune\n","from ray.rllib.agents.dqn.dqn import DQNTrainer, DEFAULT_CONFIG\n","### import self-defined function\n","import similarity_metrics\n","from utility_function import *\n","### import Environment\n","from Environment import KGRLEnv\n","### Import Customized DQN\n","from PolicyDQN import *\n","tf.__version__"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'1.15.2'"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"TI1RfQp50aTP"},"source":["## Read processed data"]},{"cell_type":"code","metadata":{"id":"-RjVvaunqTF7"},"source":["method = \"bert\" ## possible methods: \"bert\", \"bidaf\", \"qanet\"\n","########################################\n","## read preprocessed data(train/test) ##\n","########################################\n","train_data = pickle.load(open(\"./preprocessed_data/train_data.pkl\", \"rb\" ))\n","test_data = pickle.load(open(\"./preprocessed_data/test_data.pkl\", \"rb\" ))\n","test_data_types = [test_data[i]['type'] for i in range(len(test_data))]\n","\n","do_bert = False\n","if method == \"bert\":\n","  do_bert = True\n","#######################################################\n","### Obtain the pickled predition for train and test ###\n","#######################################################\n","saving_path =\"./preprocessed_data/\"\n","train_file = \"pred_train_%s.pkl\" %method ; test_file = \"pred_test_%s.pkl\" %method\n","pred_train = pickle.load(open(saving_path + train_file, \"rb\" ))\n","pred_test = pickle.load(open(saving_path + test_file, \"rb\" ))\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j5RQJb6ESWqq"},"source":["## Santity check"]},{"cell_type":"code","metadata":{"id":"_wonczRbzhzE"},"source":["##################\n","## santity check #\n","##################\n","## check the length of pickled answer\n","for k,v in pred_train.items():\n","  assert len(v) == 10, \"%s does not match\" %k\n","\n","for k,v in pred_test.items():\n","  assert len(v) == 10, \"%s does not match\" %k\n","\n","#### check the length of example_similarity_features\n","ans = '65nm'\n","reference_values = ['16nm FinFET', '16nm FinFET', '14nm FinFET', '28纳米', '65nm',\n","        '28纳米', '16nm FinFET']\n","example_similarity_features = get_sim_features(ans, reference_values, do_bert = do_bert)\n","len_similarity_features = len(example_similarity_features)\n","print(len_similarity_features)\n","print(example_similarity_features)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_jtxcAwN1Oxo"},"source":["## Baseline Performance"]},{"cell_type":"code","metadata":{"id":"Dnitp0JG1ODM"},"source":["print(\"+\" * 30 + \" For method %s, the scores are \" %method + \"+\" * 30)\n","avg_score = []\n","oracle_score = []\n","max_conf_score = []\n","majority_vote_score = []\n","first_score = []\n","\n","flatten = lambda l: [item for sublist in l for item in sublist]\n","for i in range(len(test_data)):\n","  cur = pred_test['Test_'+str(i)]\n","  candidate_answer = [cur[j][0][0] for j in range(len(cur))]\n","  confs = [cur[j][1][0] for j in range(len(cur))]\n","  if do_bert: ## if do bert the object should be preprocessed as original bert paper\n","    sims = [similarity_metrics.LevenSim(c, token_word(test_data[i]['o']) ) for c in candidate_answer]\n","  else:\n","    sims = [similarity_metrics.LevenSim(c, test_data[i]['o']) for c in candidate_answer]\n","  # majority vote\n","  c = Counter(candidate_answer)\n","  ans_majority_vote, _ = c.most_common()[0]\n","  first_score.append(sims[0])\n","  avg_score.append(np.mean(sims))\n","  max_conf_score.append(sims[np.argmax(confs)])\n","  majority_vote_score.append(similarity_metrics.LevenSim(ans_majority_vote, \n","                                                         test_data[i]['o']))\n","  oracle_score.append(np.max(sims))\n","\n","test_data_types = [test_data[i]['type'] for i in range(len(test_data))]\n","GPU_test_index = [i for i in range(len(test_data)) if test_data_types[i] == 'GPUs']\n","Game_test_index = [i for i in range(len(test_data)) if test_data_types[i] == 'Games']\n","Movie_test_index = [i for i in range(len(test_data)) if test_data_types[i] == 'Movies']\n","Phone_test_index = [i for i in range(len(test_data)) if test_data_types[i] == 'phones']\n","\n","## print the scores \n","\n","print(\"first score is %0.3f (Overall)\"%np.mean(np.array(first_score)))\n","print(\"avg score is %0.3f (Overall)\"%np.mean(np.array(avg_score)))\n","print(\"mac conf score is %0.3f (Overall)\"%np.mean(np.array(max_conf_score)))\n","print(\"majority vote score is %0.3f (Overall)\"%np.mean(np.array(majority_vote_score)))\n","print(\"oracle score is %0.3f (Overall)\"%np.mean(np.array(oracle_score)))\n","\n","index_to_use = GPU_test_index\n","print(\"first score is %0.3f for GPU\"%np.mean(np.array(first_score)[index_to_use]))\n","print(\"avg score is %0.3f for GPU\"%np.mean(np.array(avg_score)[index_to_use]))\n","print(\"mac conf score is %0.3f for GPU\"%np.mean(np.array(max_conf_score)[index_to_use]))\n","print(\"majority vote score is %0.3f for GPU\"%np.mean(np.array(majority_vote_score)[index_to_use]))\n","print(\"oracle score is %0.3f for GPU\"%np.mean(np.array(oracle_score)[index_to_use]))\n","\n","index_to_use = Game_test_index\n","print(\"first score is %0.3f for GAME\"%np.mean(np.array(first_score)[index_to_use]))\n","print(\"avg score is %0.3f for GAME\"%np.mean(np.array(avg_score)[index_to_use]))\n","print(\"mac conf score is %0.3f for GAME\"%np.mean(np.array(max_conf_score)[index_to_use]))\n","print(\"majority vote score is %0.3f for GAME\"%np.mean(np.array(majority_vote_score)[index_to_use]))\n","print(\"oracle score is %0.3f for GAME\"%np.mean(np.array(oracle_score)[index_to_use]))\n","\n","index_to_use = Movie_test_index\n","print(\"first score is %0.3f for MOVIE\"%np.mean(np.array(first_score)[index_to_use]))\n","print(\"avg score is %0.3f for MOVIE\"%np.mean(np.array(avg_score)[index_to_use]))\n","print(\"mac conf score is %0.3f for MOVIE\"%np.mean(np.array(max_conf_score)[index_to_use]))\n","print(\"majority vote score is %0.3f for MOVIE\"%np.mean(np.array(majority_vote_score)[index_to_use]))\n","print(\"oracle score is %0.3f for MOVIE\"%np.mean(np.array(oracle_score)[index_to_use]))\n","\n","index_to_use = Phone_test_index\n","print(\"first score is %0.3f for PHONE\"%np.mean(np.array(first_score)[index_to_use]))\n","print(\"avg score is %0.3f for PHONE\"%np.mean(np.array(avg_score)[index_to_use]))\n","print(\"mac conf score is %0.3f for PHONE\"%np.mean(np.array(max_conf_score)[index_to_use]))\n","print(\"majority vote score is %0.3f for PHONE\"%np.mean(np.array(majority_vote_score)[index_to_use]))\n","print(\"oracle score is %0.3f for PHONE\"%np.mean(np.array(oracle_score)[index_to_use]))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3a6CuDDp55dO"},"source":["## Train"]},{"cell_type":"code","metadata":{"id":"25YrNMHp4pDN"},"source":["seed = 20201015\n","np.random.seed(seed)\n","tf.random.set_random_seed(seed)\n","ray.init(num_gpus=1, log_to_driver=False, local_mode=True, ignore_reinit_error=True)\n","ModelCatalog.register_custom_model(\"keras_q_model\", DQNModel)\n","\n","qTrainer = DQNTrainer(env=KGRLEnv, config={# config to pass to env class\n","    \"model\": {\n","        \"custom_model\": \"keras_q_model\"\n","    },\n","    \"seed\" : seed,\n","    \"env_config\": {\"training\": True, \"idx_to_test\":None, \"train_data\" : train_data,\"test_data\": test_data,\"pred_train\":  pred_train, \"pred_test\" : pred_test, \"do_bert\" : do_bert},\n","    \"buffer_size\":100,\n","    \"lr_schedule\": [[0, 0.05], [20, 0.01], [30, 0.005], [50, 0.001]],\n","    \"train_batch_size\":100\n","  })\n","\n","\n","total_iteration = 20\n","prev_time = time.time()\n","for i in range(total_iteration):\n","    print(\"iteration {};\".format(i), \\\n","          \"%d sec/iteration;\" % (time.time()- prev_time), \\\n","          \"%d min remaining\" % ((total_iteration - i)*(time.time()- prev_time)/60))\n","    prev_time = time.time()\n","    qTrainer.train()\n","    \n","print(\"Training Done!\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cAC4IzIRBjrV"},"source":["## Evaluation"]},{"cell_type":"code","metadata":{"id":"R7sk510J5Nmg","executionInfo":{"status":"ok","timestamp":1603065091617,"user_tz":240,"elapsed":36911,"user":{"displayName":"Sheng Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhraDPO3yxolOf82I55EVZaIAfn4g1oUU6mSS7k=s64","userId":"16336041814041002028"}},"outputId":"5703dc1b-43b0-4901-d9aa-fa6bd02a1c7a","colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["def evaluation_q(test_data, pred_test, qTrainer):\n","    rewards = []\n","    steps = []\n","    for i in range(len(test_data)):\n","      env = KGRLEnv({\"training\": False, \"idx_to_test\":i, \"train_data\" : None, \"test_data\": test_data,\"pred_train\":  None, \"pred_test\" : pred_test, \"do_bert\" : do_bert})\n","      state = env.state\n","      done = False\n","      while not done:\n","          action = qTrainer.compute_action(state)\n","          state, reward, done, results = env.step(action)\n","      rewards.append(reward)\n","      steps.append(results['steps'])\n","    return rewards, steps\n","\n","reward_list, step_list = evaluation_q(test_data, pred_test, qTrainer)\n","avg_reward = np.mean(reward_list)\n","avg_steps = np.mean(step_list)\n","\n","GPU_reward = np.mean(np.array(reward_list)[GPU_test_index])\n","GPU_steps = np.mean(np.array(step_list)[GPU_test_index])\n","\n","Movie_reward = np.mean(np.array(reward_list)[Movie_test_index])\n","Movie_steps = np.mean(np.array(step_list)[Movie_test_index])\n","\n","Game_reward = np.mean(np.array(reward_list)[Game_test_index])\n","Game_steps = np.mean(np.array(step_list)[Game_test_index])\n","\n","Phone_reward = np.mean(np.array(reward_list)[Phone_test_index])\n","Phone_steps = np.mean(np.array(step_list)[Phone_test_index])\n","print(\"Training iteration {}..., \\n average reward is {:0.3f},\\\n","average # of steps is {:0.3f}\".format(i, avg_reward, avg_steps))\n","\n","print(\"Average rewards for GPU/Movie/Game/Phone are {:0.3f}/{:0.3f}/{:0.3f}/{:0.3f}\"\\\n","      .format(GPU_reward, Movie_reward, Game_reward, Phone_reward))\n","\n","print(\"Average # of steps for GPU/Movie/Game/Phone are {:0.3f}/{:0.3f}/{:0.3f}/{:0.3f}\"\\\n","      .format(GPU_steps, Movie_steps, Game_steps, Phone_steps))\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Training iteration 9..., \n"," average reward is 0.619,average # of steps is 4.450\n","Average rewards for GPU/Movie/Game/Phone are 0.628/0.672/0.518/0.658\n","Average # of steps for GPU/Movie/Game/Phone are 4.840/3.653/5.040/4.267\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"c9opqneN1YyF"},"source":["# Ablation Study: part of KG are missing\n"]},{"cell_type":"code","metadata":{"id":"G0JQBlxZgf8s"},"source":["use_percentage = 0.5 # control the percentage of data that can leverage KG\n","\n","train_kg_index = np.random.binomial(1, use_percentage, len(train_data))\n","test_kg_index = np.random.binomial(1, use_percentage, len(test_data))\n","\n","for i in range(len(train_data)):\n","  train_data[i]['kg_index'] = train_kg_index[i]\n","for i in range(len(test_data)):\n","  test_data[i]['kg_index'] = test_kg_index[i]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aus8Prut1Xht","executionInfo":{"status":"ok","timestamp":1603072479260,"user_tz":240,"elapsed":1419,"user":{"displayName":"Sheng Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhraDPO3yxolOf82I55EVZaIAfn4g1oUU6mSS7k=s64","userId":"16336041814041002028"}},"outputId":"d9c28ad3-2bdf-4085-d60d-6cfe5ca881ee","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["class KGRLMask(gym.Env):\n","    def _build_init(self, kg_dir = \"./related_triples_by_relation/\"):\n","        \"\"\"\n","        when testing, use idx_to_test, otherwise randomly sample a training data\n","        \"\"\"\n","        if self.training:\n","          idx = np.random.choice(range(len(self.train_data))) \n","          self.entry = self.train_data[idx]\n","        else:\n","          idx = self.idx_to_test\n","          self.entry = self.test_data[idx]\n","        self.query = self.entry['s'] + ' ' + self.entry['p']\n","        self.text_list = self.entry['corpus']\n","        ######################################################\n","        ## obtain the answer from extraction system output ###\n","        ######################################################\n","        if self.training:\n","          self.answer_list = pred_train[self.entry['id']] \n","        else:\n","          self.answer_list = pred_test[self.entry['id']]\n","        self.text_answer = [[self.text_list[i], self.answer_list[i]] for i in range(len(self.text_list))]\n","        self.max_index = len(self.text_list)\n","        ### #####################################################################\n","        ## initialize the index of current/new candidate as 0/1 respectively. ###\n","        #########################################################################\n","        self.cur_index = 0\n","        self.new_index = 1\n","        self.cur = self.text_answer[self.cur_index]\n","        try:\n","          self.new = self.text_answer[self.new_index]\n","        except:\n","          ####################################################################\n","          ## exception would happen when size of raw text is less than 2. ####\n","          ## which cannot happen in preprocessed data ########################\n","          ####################################################################\n","          self.new =  self.cur\n","        self.curans = self.cur[1][0]\n","        self.newans = self.new[1][0]\n","        self.answer_seen = self.cur[1][0]\n","        self.truth = \"\".join(self.entry['o'])\n","\n","        #################################################################\n","        ## if do bert, we need to squeeze the space #####################\n","        #################################################################\n","        if do_bert:\n","          self.truth = token_word(self.truth)\n","        # get reference values\n","        filename = \"%s.csv\" % self.entry['p']\n","        related_triples_to_use = pd.read_csv(kg_dir + filename, sep='\\t', header = None)\n","        self.reference_values = related_triples_to_use[2].values\n","\n","\n","        #################################################################\n","        ## Control KG usage #############################################\n","        #################################################################\n","        self.use_kg_index = self.entry['kg_index']\n","\n","\n","    def __init__(self, env_config, T=20):\n","      \n","        \"\"\"\n","        initialize the environment\n","        \"\"\"\n","        self.idx_to_test = env_config[\"idx_to_test\"]\n","        self.training = env_config[\"training\"]\n","        self.train_data = train_data\n","        self.test_data = test_data\n","        self._counter = 0 # For terminating the episode\n","        self._build_init()\n","        self.state = self.getState(self.cur, self.new)\n","        self._horizon = env_config.get(\"T\", T)\n","        self._setup_spaces()\n","\n","    def _setup_spaces(self):\n","        ##############\n","        self.action_space = spaces.Discrete(3)\n","        self.observation_space = spaces.Box(-np.inf, np.inf, \n","                                            [1 + 2 + 2 * len_similarity_features, ])\n","        ##############\n","\n","    def step(self, action):\n","        self.new_index += 1\n","        if self.new_index >= self.max_index: # exceed the given size will stop (10 in paper)\n","            reward = similarity_metrics.LevenSim(self.curans[0], self.truth)\n","            done = True\n","            return self.state, reward, done, {\"final_answer\":self.curans,\n","                                              \"steps\": self.new_index}\n","\n","        else:\n","          if action == 0: # still use old current as current\n","              self.new = self.text_answer[self.new_index]\n","              self.newans = self.new[1][0]\n","              self.state = self.getState(self.cur, self.new)\n","              reward = 0\n","\n","          elif action == 1: # accept new as current\n","              self.cur_index = self.new_index - 1\n","              self.cur = self.text_answer[self.cur_index]\n","              self.curans = self.cur[1][0]\n","              self.new = self.text_answer[self.new_index]\n","              self.newans = self.new[1][0]\n","              self.state = self.getState(self.cur, self.new)\n","              reward = 0\n","          else:\n","              #reward = max([similarity_metrics.LevenSim(self.curans[i], self.truth) for i in range(self.K)])    #reward改成几种similarity的max\n","              \n","              reward = similarity_metrics.LevenSim(self.curans[0], self.truth)\n","              done = True\n","              return self.state, reward, done, {\"final_answer\":self.curans,\n","                                              \"steps\": self.new_index}\n","          self._counter += 1\n","          done = self._counter >= self._horizon\n","          return self.state, reward, done,  {\"final_answer\":self.curans,\n","                                              \"steps\": self.new_index}\n","\n","    def reset(self):\n","        self._build_init()\n","        self.state = self.getState(self.cur, self.new)\n","        self._counter = 0\n","        return self.state\n","\n","    def getState(self, cur, new):\n","        # input: current best text and answer, new text and answer that seen before\n","        # output: state\n","        curans = cur[1][0]\n","        newans = new[1][0]\n","        # state (1) confidence scores (dim: K*2)\n","        curconf = cur[1][1]  \n","        newconf = new[1][1]\n","\n","        # state (2) similarity between texts (dim: 1)\n","        textsim = [self.textSimilarity(cur[1], new[1])]\n","        try:\n","          textsim = [textSimilarity(cur[0], new[0])]\n","        except: \n","          textsim = [0]\n","\n","\n","        # state (3) \n","        if self.use_kg_index == 1:\n","          flatten = lambda l: [item for sublist in l for item in sublist]\n","          ref_score_cur = flatten([get_sim_features(i, self.reference_values, do_bert = do_bert) for i in curans])\n","          ref_score_new = flatten([get_sim_features(i, self.reference_values, do_bert = do_bert) for i in newans])\n","        \n","        else:\n","          ref_score_cur = ref_score_new = [0]*len_similarity_features\n","        \n","        state = curconf + newconf + ref_score_cur + ref_score_new + textsim\n","        return state\n","\n","    # function to compute cosine similarity bewteen two texts\n","    def textSimilarity(self, text1, text2):\n","        corpus = [text1, text2]\n","        vectorizer = TfidfVectorizer()\n","        try:\n","          tfidf = vectorizer.fit_transform(corpus)\n","          words = vectorizer.get_feature_names()\n","          similarity_matrix = cosine_similarity(tfidf)\n","          similarity = similarity_matrix[0][1]\n","        except:\n","          similarity = 0\n","        return similarity\n","\n","len(KGRLMask({\"training\":True, \"idx_to_test\":0}).state)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["31"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"y4zc5VJqSqcg"},"source":["ray.init(num_gpus=1, log_to_driver=False, local_mode=True, ignore_reinit_error=True)\n","ModelCatalog.register_custom_model(\"keras_q_model\", DQNModel)\n","\n","qTrainer = DQNTrainer(env=KGRLMask, config={# config to pass to env class\n","    \"model\": {\n","        \"custom_model\": \"keras_q_model\"\n","    },\n","    \"env_config\": {\"training\": True, \"idx_to_test\":None},\n","    \"buffer_size\":100,\n","    \"lr_schedule\": [[0, 0.05], [20, 0.01], [30, 0.005], [50, 0.001]],\n","    \"train_batch_size\":100\n","  })\n","\n","\n","total_iteration = 20\n","prev_time = time.time()\n","for i in range(total_iteration):\n","    print(\"iteration {};\".format(i), \\\n","          \"%d sec/iteration;\" % (time.time()- prev_time), \\\n","          \"%d min remaining\" % ((total_iteration - i)*(time.time()- prev_time)/60))\n","    prev_time = time.time()\n","    qTrainer.train()\n","print(\"Training Done!\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ot9P0N0GSrF3"},"source":["def evaluation_q(test_data, pred_test, qTrainer):\n","    rewards = []\n","    steps = []\n","    for i in range(len(test_data)):\n","      env = KGRLEnv({\"training\": False, \"idx_to_test\":i, \"train_data\" : None, \"test_data\": test_data,\"pred_train\":  None, \"pred_test\" : pred_test, \"do_bert\" : do_bert})\n","      state = env.state\n","      done = False\n","      while not done:\n","          action = qTrainer.compute_action(state)\n","          state, reward, done, results = env.step(action)\n","      rewards.append(reward)\n","      steps.append(results['steps'])\n","    return rewards, steps\n","    \n","reward_list, step_list = evaluation_q(test_data, pred_test, qTrainer)\n","avg_reward = np.mean(reward_list)\n","avg_steps = np.mean(step_list)\n","\n","GPU_reward = np.mean(np.array(reward_list)[GPU_test_index])\n","GPU_steps = np.mean(np.array(step_list)[GPU_test_index])\n","\n","Movie_reward = np.mean(np.array(reward_list)[Movie_test_index])\n","Movie_steps = np.mean(np.array(step_list)[Movie_test_index])\n","\n","Game_reward = np.mean(np.array(reward_list)[Game_test_index])\n","Game_steps = np.mean(np.array(step_list)[Game_test_index])\n","\n","Phone_reward = np.mean(np.array(reward_list)[Phone_test_index])\n","Phone_steps = np.mean(np.array(step_list)[Phone_test_index])\n","\n","\n","print(\"Training iteration {}..., \\n average reward is {:0.3f},\\\n","average # of steps is {:0.3f}\".format(i, avg_reward, avg_steps))\n","\n","print(\"Average rewards for GPU/Movie/Game/Phone are {:0.3f}/{:0.3f}/{:0.3f}/{:0.3f}\"\\\n","      .format(GPU_reward, Movie_reward, Game_reward, Phone_reward))\n","\n","print(\"Average # of steps for GPU/Movie/Game/Phone are {:0.3f}/{:0.3f}/{:0.3f}/{:0.3f}\"\\\n","      .format(GPU_steps, Movie_steps, Game_steps, Phone_steps))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s7VjTQnRIswx"},"source":[""],"execution_count":null,"outputs":[]}]}